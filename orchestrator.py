import streamlit as st
import json
import datetime
from skill_library import lookup_concept
from ai_tools import get_khong_minh_luc_dieu, get_lunar_date_offline

class AIOrchestrator:
    """
    Simulates an n8n-style workflow orchestration.
    Coordinates specialized Agents (Nodes) to answer user queries accurately.
    """
    
    def __init__(self, gemini_helper):
        self.gemini = gemini_helper
        self.logs = [] # Execution logs to show in UI
        
    def log_step(self, step_name, status, detail=""):
        entry = {
            "time": datetime.datetime.now().strftime("%H:%M:%S"),
            "step": step_name,
            "status": status,
            "detail": detail
        }
        self.logs.append(entry)
        
    def run_pipeline(self, user_question, current_topic="Chung", chart_data=None, mai_hoa_data=None, luc_hao_data=None):
        """
        Main Workflow Entry Point.
        Flow:
        1. Intent Analysis Node (Router)
        2. Knowledge Retrieval Node (Worker) - Now includes [LIVE BOARD DATA]
        3. Context Memory Node
        4. Synthesis Node (Writer)
        """
        self.logs = [] # Reset logs
        final_answer = ""
        knowledge_context = ""
        
        # --- NODE 0: LIVE DATA INGESTION ---
        live_context = self._format_live_context(chart_data, mai_hoa_data, luc_hao_data)
        if live_context:
            knowledge_context += f"\n[D·ªÆ LI·ªÜU B√ÄN C·ªú ƒêANG HI·ªÇN TH·ªä (LIVE DATA)]:\n{live_context}\n"
            self.log_step("Live Data Ingestion", "SUCCESS", "Captured current Board/Hexagram state.")
        else:
            self.log_step("Live Data Ingestion", "SKIPPED", "No active chart/hexagram found.")

        # --- NODE 1: INTENT ROUTER ---
        self.log_step("Intent Analysis", "RUNNING", "Analyzing user question...")
        intent = "GENERAL"
        
        q_lower = user_question.lower()
        
        # Priority 1: Time Calculation (Specific tool required)
        if any(x in q_lower for x in ["gi·ªù t·ªët", "xu·∫•t h√†nh", "kh·ªïng minh", "t√≠nh gi·ªù"]):
            intent = "CALCULATION"
            
        # Priority 2: Timing / Forecast (When?)
        elif any(x in q_lower for x in ["khi n√†o", "bao l√¢u", "th√°ng m·∫•y", "nƒÉm n√†o", "·ª©ng k·ª≥", "th·ªùi gian", "l√∫c n√†o", "ng√†y n√†o"]):
            intent = "TIMING"
            
        # Priority 3: Personality / People / Profiles
        elif any(x in q_lower for x in ["t√≠nh c√°ch", "con ng∆∞·ªùi", "ngo·∫°i h√¨nh", "t√¢m t√≠nh", "trai", "g√°i", "nam", "n·ªØ", "l√† ai", "ng∆∞·ªùi n√†o", "c·ªßa ai", "gh√©t", "th∆∞∆°ng", "ai", "ƒë√†n √¥ng", "ph·ª• n·ªØ", "con trai", "con g√°i", "ƒë·ªëi ph∆∞∆°ng"]):
            intent = "PROFILE"
            
        # Priority 4: Remedy / Items
        elif any(x in q_lower for x in ["h√≥a gi·∫£i", "v·∫≠t ph·∫©m", "l√†m g√¨ ƒë·ªÉ", "linh v·∫≠t"]):
            intent = "REMEDY"
            
        # Priority 5: Weather
        elif any(x in q_lower for x in ["m∆∞a", "n·∫Øng", "th·ªùi ti·∫øt", "b√£o"]):
            intent = "WEATHER"
            
        # Priority 6: Definitions / Terms
        elif any(x in q_lower for x in ["l√† g√¨", "√Ω nghƒ©a", "gi·∫£i th√≠ch", "ƒë·ªãnh nghƒ©a"]):
            intent = "DEFINITION"
            
        # Priority 7: Analysis / Review Table
        elif any(x in q_lower for x in ["lu·∫≠n gi·∫£i", "ph√¢n t√≠ch", "ƒë√°nh gi√°", "xem gi√∫p", "nh∆∞ th·∫ø n√†o"]):
            intent = "ANALYSIS"
            
        self.log_step("Intent Analysis", "COMPLETED", f"Detected Intent: {intent}")
        
        # --- NODE 2: KNOWLEDGE RETRIEVAL ---
        self.log_step("Knowledge Retrieval", "RUNNING", f"Fetching data for {intent}...")
        
        # Sub-Node: Time Horizon Hint
        time_horizon = "FUTURE"
        if any(x in q_lower for x in ["ƒë√£", "v·ª´a m·ªõi", "qu√° kh·ª©", "tr∆∞·ªõc ƒë√¢y"]):
            time_horizon = "PAST"
        knowledge_context += f"\n[G·ª¢I √ù TH·ªúI ƒêI·ªÇM]: {time_horizon}\n"

        # Sub-Node: Dictionary Skill
        dict_data = lookup_concept(user_question)
        if dict_data:
            self.log_step("Dictionary Skill", "SUCCESS", f"Found definition for input term.")
            knowledge_context += f"\n[üìñ T·ª™ ƒêI·ªÇN CHUY√äN NG√ÄNH]: {dict_data['summary']}\nChi ti·∫øt: {dict_data['details']}\n"
        
        # Sub-Node: Object Mapping (ALWAYS INJECT FOR CONTEXT)
        dung_than_data = lookup_concept("d·ª•ng th·∫ßn")
        if dung_than_data:
             knowledge_context += f"\n[üîç B·∫¢NG TRA C·ª®U ƒê·ªêI T∆Ø·ª¢NG (D·ª§NG TH·∫¶N)]: {dung_than_data['summary']}\nChi ti·∫øt: {dung_than_data['details']}\n"
             self.log_step("Object Mapping", "SUCCESS", "Loaded Reference Objects Table.")

        # Sub-Node: Timing/Remedy/Weather Skill logic dispatch
        for skill_key, skill_intent in [("·ª©ng k·ª≥", "TIMING"), ("h√≥a gi·∫£i", "REMEDY"), ("th·ªùi ti·∫øt", "WEATHER")]:
            if intent == skill_intent:
                skill_data = lookup_concept(skill_key)
                if skill_data:
                     knowledge_context += f"\n[üîç QUY T·∫ÆC CHU·∫®N - {skill_key.upper()}]:\n{skill_data['details']}\n"
                     self.log_step(f"{skill_key.capitalize()} Skill", "SUCCESS", f"Loaded Rules for {skill_intent}")
        
        # Sub-Node: Personality & Gender Profiling Skill
        if intent == "PROFILE":
            profile_data = lookup_concept("t√≠nh c√°ch")
            gender_data = lookup_concept("nam n·ªØ")
            
            if profile_data:
                 knowledge_context += f"\n[üë§ T·ª™ ƒêI·ªÇN T√çNH C√ÅCH]:\n{profile_data['details']}\n"
            if gender_data:
                 knowledge_context += f"\n[‚ößÔ∏è QUY T·∫ÆC XEM GI·ªöI T√çNH (Nam/N·ªØ)]:\n{gender_data['details']}\n"
            
            self.log_step("Profile Skill", "SUCCESS", "Loaded Profile & Gender Rules.")

        # Sub-Node: Time Calculation Skill
        if intent == "CALCULATION":
            try:
                d_val = datetime.datetime.now()
                if hasattr(st, 'session_state') and 'selected_date' in st.session_state:
                     d_val = st.session_state.selected_date
                lm, ld = get_lunar_date_offline(d_val)
                summ, det = get_khong_minh_luc_dieu(lm, ld)
                knowledge_context += f"\n[‚è±Ô∏è T√çNH TO√ÅN TH·ªúI GIAN]:\n{summ}\n{det}\n"
                self.log_step("Time Calc Skill", "SUCCESS", f"Calculated for Lunar Date {ld}/{lm}")
            except Exception as e:
                self.log_step("Time Calc Skill", "ERROR", str(e))
                
        # Sub-Node: Topic Context (ONLY if not a standalone definition/timing/profile question)
        import qmdg_data
        topic_dict = getattr(qmdg_data, 'TOPIC_INTERPRETATIONS', {})
        
        # If user asks a general definition or profile, the UI topic (e.g. Selling House) 
        # often distracts. We only inject it if intent is ANALYSIS or GENERAL.
        if intent in ["ANALYSIS", "GENERAL"] and current_topic in topic_dict:
             t_data = topic_dict[current_topic]
             knowledge_context += f"\n[CH·ª¶ ƒê·ªÄ ƒêANG XEM TR√äN UI]: {current_topic}\n- D·ª•ng th·∫ßn chu·∫©n: {t_data.get('D·ª•ng_Th·∫ßn')}\n- G·ª£i √Ω lu·∫≠n gi·∫£i: {t_data.get('Lu·∫≠n_Gi·∫£i_G·ª£i_√ù')}\n"
        
        self.log_step("Knowledge Retrieval", "COMPLETED", "Data gathering finished.")
        
        # --- NODE 3: CONTEXT MEMORY ---
        self.log_step("Context Memory", "RUNNING", "Retrieving session history...")
        history_context = ""
        if hasattr(st, 'session_state') and 'chat_history' in st.session_state:
            # Take last 3 exchanges for context
            recent_history = st.session_state.chat_history[-6:] 
            history_context = "\n[L·ªäCH S·ª¨ TR√í CHUY·ªÜN G·∫¶N ƒê√ÇY]:\n"
            for msg in recent_history:
                role = "B·∫°n" if msg["role"] == "user" else "AI"
                history_context += f"- {role}: {msg['content'][:100]}...\n"
        self.log_step("Context Memory", "SUCCESS", "Internal memory updated.")

        # --- NODE 4: SYNTHESIS ---
        self.log_step("Gemini Synthesis", "RUNNING", "Generating final response...")
        
        # Construct Prompt
        system_prompt = (
            f"VAI TR√í: B·∫°n l√† H·ªá th·ªëng SI√äU TR√ç TU·ªÜ K·ª≤ M√îN (Orchestrated AI).\n"
            f"B·∫†N PH·∫¢I TR·∫¢ L·ªúI CH√çNH X√ÅC THEO C√ÅC NGU·ªíN D·ªÆ LI·ªÜU ƒê∆Ø·ª¢C CUNG C·∫§P D∆Ø·ªöI ƒê√ÇY:\n"
            f"{history_context}\n"
            f"{knowledge_context}\n"
            f"--------------------------------------------------\n"
            f"C√ÇU H·ªéI NG∆Ø·ªúI D√ôNG: '{user_question}'\n\n"
            f"QUY T·∫ÆC B·∫ÆT BU·ªòC:\n"
            f"1. B·∫ÆT BU·ªòC cƒÉn c·ª© v√†o [D·ªÆ LI·ªÜU B√ÄN C·ªú ƒêANG HI·ªÇN TH·ªä] (K·ª≥ M√¥n, Mai Hoa, Kinh D·ªãch) ƒë·ªÉ ƒë∆∞a ra k·∫øt lu·∫≠n. KH√îNG TR·∫¢ L·ªúI CHUNG CHUNG.\n"
            f"2. B·∫ÆT BU·ªòC x√°c ƒë·ªãnh ƒë√∫ng ƒë·ªëi t∆∞·ª£ng (D·ª•ng Th·∫ßn) c·∫ßn xem t·ª´ [B·∫¢NG TRA C·ª®U ƒê·ªêI T∆Ø·ª¢NG].\n"
            f"3. X√°c ƒë·ªãnh ƒë√∫ng th·ªùi ƒëi·ªÉm (Qu√° kh·ª©/Hi·ªán t·∫°i/T∆∞∆°ng lai) t·ª´ ƒë·ªÅ b√†i v√† [G·ª¢I √ù TH·ªúI ƒêI·ªÇM] ƒë·ªÉ tr·∫£ l·ªùi ph√π h·ª£p.\n"
            f"4. N·∫øu c√≥ d·ªØ li·ªáu [üìñ T·ª™ ƒêI·ªÇN] ho·∫∑c [‚ößÔ∏è GI·ªöI T√çNH], b·∫°n ph·∫£i d√πng ƒë√∫ng ƒë·ªãnh nghƒ©a ƒë√≥. KH√îNG ƒê∆Ø·ª¢C T·ª∞ √ù THAY ƒê·ªîI.\n"
            f"5. N·∫øu h·ªèi v·ªÅ th·ªùi gian (Khi n√†o), h√£y √°p d·ª•ng ƒë√∫ng [‚è≥ QUY T·∫ÆC ·ª®NG K·ª≤]. Gi·∫£i th√≠ch r√µ t·∫°i sao.\n"
            f"6. TR√åNH B√ÄY: \n"
            f"   - B·∫Øt ƒë·∫ßu b·∫±ng kh·ªëi [SUY_LUAN] gi·∫£i th√≠ch logic t√¨m ki·∫øm th√¥ng tin.\n"
            f"   - K·∫øt th√∫c b·∫±ng [KET_LUAN] ƒë∆∞a ra c√¢u tr·∫£ l·ªùi cu·ªëi c√πng s√∫c t√≠ch, chu·∫©n x√°c s√°ch v·ªü.\n"
            f"   - QUY T·∫ÆC C√î L·∫¨P NHI·ªÜM V·ª§: N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ con ng∆∞·ªùi (trai/g√°i), th·ªùi ti·∫øt, hay th·ªùi gian, h√£y B·ªé QUA HO√ÄN TO√ÄN c√°c ch·ªß ƒë·ªÅ m·∫∑c ƒë·ªãnh nh∆∞ 'B√°n nh√† ƒë·∫•t', 'Ki·ªán t·ª•ng' ƒëang c√≥ tr√™n UI. Ch·ªâ t·∫≠p trung v√†o vi·ªác tra c·ª©u D·ª•ng Th·∫ßn t∆∞∆°ng ·ª©ng trong d·ªØ li·ªáu chuy√™n ng√†nh.\n"
            f"7. TUY·ªÜT ƒê·ªêI ∆∞u ti√™n d·ªØ li·ªáu trong [T·ª™ ƒêI·ªÇN] v√† [B·∫¢NG TRA C·ª®U] h∆°n l√† ki·∫øn th·ª©c t·ªïng qu√°t c·ªßa AI. N·∫øu s√°ch quy ƒë·ªãnh l√† Nam, b·∫°n kh√¥ng ƒë∆∞·ª£c t·ª± √Ω tr·∫£ l·ªùi l√† N·ªØ."
        )
        
        final_answer = self.gemini._call_ai(system_prompt)
        return final_answer

    def _format_live_context(self, qmdg, mai_hoa, luc_hao):
        """Helper to turn complex state into readable text for AI"""
        context = ""
        
        # 1. QMDG Grid
        if qmdg:
            context += "--- K·ª≤ M√îN ƒê·ªòN GI√ÅP ---\n"
            # Extract basic 4 pillars if available
            context += f"T·ª© tr·ª•: {qmdg.get('can_nam')} {qmdg.get('chi_nam')} / {qmdg.get('can_thang')} {qmdg.get('chi_thang')} / {qmdg.get('can_ngay')} {qmdg.get('chi_ngay')} / {qmdg.get('can_gio')} {qmdg.get('chi_gio')}\n"
            context += f"Ti·∫øt kh√≠: {qmdg.get('tiet_khi')} | C·ª•c: {qmdg.get('cuc')} {'D∆∞∆°ng' if qmdg.get('is_duong_don') else '√Çm'}\n"
            
            # Extract 9 palaces
            for i in range(1, 10):
                sao = qmdg.get('thien_ban', {}).get(i, "N/A")
                mon = qmdg.get('nhan_ban', {}).get(i, "N/A")
                than = qmdg.get('than_ban', {}).get(i, "N/A")
                c_thien = qmdg.get('can_thien_ban', {}).get(i, "N/A")
                c_dia = qmdg.get('dia_can', {}).get(i, "N/A")
                context += f"- Cung {i}: {sao}, {mon}, {than}, Thi√™n Can {c_thien} l√¢m {c_dia}\n"

        # 2. Mai Hoa
        if mai_hoa:
            context += "\n--- MAI HOA D·ªäCH S·ªê ---\n"
            context += f"Qu·∫ª Ch√≠nh: {mai_hoa.get('ten')} (Th·ªÉ: {mai_hoa.get('ten_the')}, D·ª•ng: {mai_hoa.get('ten_dung')})\n"
            context += f"Quan h·ªá Ng≈© h√†nh: {mai_hoa.get('upper_element')} / {mai_hoa.get('lower_element')}\n"
            context += f"T∆∞·ª£ng Qu·∫ª: {mai_hoa.get('tuong')}\n"
            context += f"Qu·∫ª Bi·∫øn: {mai_hoa.get('ten_qua_bien')} (ƒê·ªông h√†o {mai_hoa.get('dong_hao')})\n"

        # 3. L·ª•c H√†o
        if luc_hao:
            context += "\n--- L·ª§C H√ÄO ---\n"
            context += f"Qu·∫ª: {luc_hao.get('ten_que')}\n"
            context += f"D·ª•ng Th·∫ßn: {luc_hao.get('dung_than_label')}\n"
            context += f"Tr·∫°ng th√°i Th·∫ø/·ª®ng: {luc_hao.get('the_ung_interaction')}\n"
            
        return context
        
    def render_logs(self):
        """Render the n8n-style execution steps in Streamlit"""
        st.markdown("### ‚öôÔ∏è Quy Tr√¨nh X·ª≠ L√Ω (System Workflow)")
        for log in self.logs:
            icon = "‚úÖ" if log['status'] in ["SUCCESS", "COMPLETED"] else "üîÑ"
            if log['status'] == "ERROR": icon = "‚ùå"
            
            with st.expander(f"{icon} {log['step']} - {log['status']}", expanded=False):
                st.write(f"**Time:** {log['time']}")
                st.write(f"**Detail:** {log['detail']}")


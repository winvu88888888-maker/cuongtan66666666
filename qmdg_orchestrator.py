import streamlit as st
import json
import datetime
from skill_library import lookup_concept
from ai_tools import get_khong_minh_luc_dieu, get_lunar_date_offline

class AIOrchestrator:
    """
    Simulates an n8n-style workflow orchestration.
    Coordinates specialized Agents (Nodes) to answer user queries accurately.
    """
    
    def __init__(self, gemini_helper):
        self.gemini = gemini_helper
        self.logs = [] # Execution logs to show in UI
        
    def log_step(self, step_name, status, detail=""):
        entry = {
            "time": datetime.datetime.now().strftime("%H:%M:%S"),
            "step": step_name,
            "status": status,
            "detail": detail
        }
        self.logs.append(entry)
        
    def run_pipeline(self, user_question, current_topic="Chung", chart_data=None, mai_hoa_data=None, luc_hao_data=None):
        """
        Main Workflow Entry Point.
        Flow:
        1. Intent Analysis Node (Router)
        2. Knowledge Retrieval Node (Worker) - Now includes [LIVE BOARD DATA]
        3. Context Memory Node
        4. Synthesis Node (Writer)
        """
        self.logs = [] # Reset logs
        final_answer = ""
        knowledge_context = ""
        
        # --- NODE 0: LIVE DATA INGESTION ---
        live_context = self._format_live_context(chart_data, mai_hoa_data, luc_hao_data)
        if live_context:
            knowledge_context += f"\n[D·ªÆ LI·ªÜU B√ÄN C·ªú ƒêANG HI·ªÇN TH·ªä (LIVE DATA)]:\n{live_context}\n"
            self.log_step("Live Data Ingestion", "SUCCESS", "Captured current Board/Hexagram state.")
        else:
            self.log_step("Live Data Ingestion", "SKIPPED", "No active chart/hexagram found.")
        
        # --- NODE 1: INTENT ROUTER (Regex Enhanced) ---
        self.log_step("Intent Analysis", "RUNNING", "Analyzing user question...")
        import re
        q_lower = f" {user_question.lower()} " # Padding for boundary matching
        intent = "GENERAL"

        # Regex Helpers
        def match_any(keywords, text):
            return any(re.search(rf"\b{kw}\b", text) for kw in keywords)

        # 1. Calculation
        if match_any(["gi·ªù t·ªët", "xu·∫•t h√†nh", "kh·ªïng minh", "t√≠nh gi·ªù", "gi·ªù n√†o"], q_lower):
            intent = "CALCULATION"
        # 2. Timing
        elif match_any(["khi n√†o", "bao gi·ªù", "bao l√¢u", "th√°ng m·∫•y", "nƒÉm n√†o", "ng√†y n√†o", "m·∫•y gi·ªù", "ƒë·∫øn l√∫c n√†o"], q_lower):
            intent = "TIMING"
        # 3. People / Profile
        elif match_any(["ai", "ng∆∞·ªùi", "trai", "g√°i", "nam", "n·ªØ", "gh√©t", "th∆∞∆°ng", "t√≠nh c√°ch", "b·∫£n t√≠nh"], q_lower):
            intent = "PROFILE"
        # 4. Remedy
        elif match_any(["h√≥a gi·∫£i", "c√°ch s·ª≠a", "l√†m g√¨", "ƒë·ªëi ph√≥"], q_lower):
            intent = "REMEDY"
        # 5. Definition
        elif match_any(["l√† g√¨", "√Ω nghƒ©a", "gi·∫£i th√≠ch", "ƒë·ªãnh nghƒ©a"], q_lower):
            intent = "DEFINITION"
        # 6. Analysis
        elif match_any(["lu·∫≠n gi·∫£i", "ph√¢n t√≠ch", "ƒë√°nh gi√°", "xem gi√∫p", "nh∆∞ th·∫ø n√†o"], q_lower):
            intent = "ANALYSIS"
            
        self.log_step("Intent Analysis", "COMPLETED", f"Detected Intent: {intent}")
        
        # --- NODE 2: KNOWLEDGE RETRIEVAL ---
        self.log_step("Knowledge Retrieval", "RUNNING", f"Fetching data for {intent}...")
        
        # Sub-Node: Forced Topic Override (Security against hallucinations)
        # If question is about people or timing, we MUST NOT distract with UI topics like 'B√°n nh√†'.
        people_time_keywords = ["ai", "ng∆∞·ªùi", "trai", "g√°i", "nam", "n·ªØ", "khi n√†o", "bao gi·ªù", "l√∫c n√†o", "m·∫•y gi·ªù", "gh√©t", "th∆∞∆°ng"]
        topic_override = any(kw in q_lower for kw in people_time_keywords) or intent in ["PROFILE", "TIMING"]
        
        # Sub-Node: Time Horizon Hint
        time_horizon = "FUTURE"
        if any(x in q_lower for x in ["ƒë√£", "v·ª´a m·ªõi", "qu√° kh·ª©", "tr∆∞·ªõc ƒë√¢y"]):
            time_horizon = "PAST"
        knowledge_context += f"\n[G·ª¢I √ù TH·ªúI ƒêI·ªÇM]: {time_horizon}\n"

        # Sub-Node: Dictionary Skill
        dict_data = lookup_concept(user_question)
        if dict_data:
            self.log_step("Dictionary Skill", "SUCCESS", f"Found definition for input term.")
            knowledge_context += f"\n[üìñ T·ª™ ƒêI·ªÇN CHUY√äN NG√ÄNH]: {dict_data['summary']}\nChi ti·∫øt: {dict_data['details']}\n"
        
        # Sub-Node: Object Mapping (ALWAYS INJECT FOR CONTEXT)
        dung_than_data = lookup_concept("d·ª•ng th·∫ßn")
        if dung_than_data:
             knowledge_context += f"\n[üîç B·∫¢NG TRA C·ª®U ƒê·ªêI T∆Ø·ª¢NG (D·ª§NG TH·∫¶N)]: {dung_than_data['summary']}\nChi ti·∫øt: {dung_than_data['details']}\n"
             self.log_step("Object Mapping", "SUCCESS", "Loaded Reference Objects Table.")

        # Sub-Node: Timing/Remedy/Weather Skill logic dispatch
        for skill_key, skill_intent in [("·ª©ng k·ª≥", "TIMING"), ("h√≥a gi·∫£i", "REMEDY"), ("th·ªùi ti·∫øt", "WEATHER")]:
            if intent == skill_intent:
                skill_data = lookup_concept(skill_key)
                if skill_data:
                     knowledge_context += f"\n[üîç QUY T·∫ÆC CHU·∫®N - {skill_key.upper()}]:\n{skill_data['details']}\n"
                     self.log_step(f"{skill_key.capitalize()} Skill", "SUCCESS", f"Loaded Rules for {skill_intent}")
        
        # Sub-Node: Personality & Gender Profiling Skill
        if intent == "PROFILE" or any(kw in q_lower for kw in ["t√≠nh c√°ch", "nam", "n·ªØ", "trai", "g√°i", "ai"]):
            profile_data = lookup_concept("t√≠nh c√°ch")
            gender_data = lookup_concept("nam n·ªØ")
            
            if profile_data:
                 knowledge_context += f"\n[üë§ T·ª™ ƒêI·ªÇN T√çNH C√ÅCH]:\n{profile_data['details']}\n"
            if gender_data:
                 knowledge_context += f"\n[‚ößÔ∏è QUY T·∫ÆC XEM GI·ªöI T√çNH (Nam/N·ªØ)]:\n{gender_data['details']}\n"
            
            self.log_step("Profile Skill", "SUCCESS", "Loaded Profile & Gender Rules.")

        # Sub-Node: Topic Context (ONLY if not a standalone definition/timing/profile question)
        if not topic_override and intent in ["ANALYSIS", "GENERAL", "DEFINITION"]:
            import qmdg_data
            topic_dict = getattr(qmdg_data, 'TOPIC_INTERPRETATIONS', {})
            if current_topic in topic_dict:
                 t_data = topic_dict[current_topic]
                 knowledge_context += f"\n[CH·ª¶ ƒê·ªÄ ƒêANG XEM TR√äN UI]: {current_topic}\n- D·ª•ng th·∫ßn chu·∫©n: {t_data.get('D·ª•ng_Th·∫ßn')}\n- G·ª£i √Ω lu·∫≠n gi·∫£i: {t_data.get('Lu·∫≠n_Gi·∫£i_G·ª£i_√ù')}\n"
                 self.log_step("Topic Context", "SUCCESS", f"Injected context for {current_topic}")
        else:
            self.log_step("Topic Context", "SKIPPED", "Ignored UI topic to focus on specific Person/Time query.")
        
        # Sub-Node: Time Calculation Skill
        if intent == "CALCULATION":
            try:
                import datetime
                d_val = datetime.datetime.now()
                if hasattr(st, 'session_state') and 'selected_date' in st.session_state:
                     d_val = st.session_state.selected_date
                from ai_tools import get_lunar_date_offline, get_khong_minh_luc_dieu
                lm, ld = get_lunar_date_offline(d_val)
                summ, det = get_khong_minh_luc_dieu(lm, ld)
                knowledge_context += f"\n[‚è±Ô∏è T√çNH TO√ÅN TH·ªúI GIAN]:\n{summ}\n{det}\n"
                self.log_step("Time Calc Skill", "SUCCESS", f"Calculated for Lunar Date {ld}/{lm}")
            except Exception as e:
                self.log_step("Time Calc Skill", "ERROR", str(e))

        self.log_step("Knowledge Retrieval", "COMPLETED", "Data gathering finished.")
        
        # --- NODE 3: CONTEXT MEMORY ---
        self.log_step("Context Memory", "RUNNING", "Retrieving session history...")
        history_context = ""
        if hasattr(st, 'session_state') and 'chat_history' in st.session_state:
            # Take last 3 exchanges for context
            recent_history = st.session_state.chat_history[-6:] 
            history_context = "\n[L·ªäCH S·ª¨ TR√í CHUY·ªÜN G·∫¶N ƒê√ÇY]:\n"
            for msg in recent_history:
                role = "B·∫°n" if msg["role"] == "user" else "AI"
                history_context += f"- {role}: {msg['content'][:100]}...\n"
        self.log_step("Context Memory", "SUCCESS", "Internal memory updated.")

        # --- NODE 4: SYNTHESIS ---
        self.log_step("Gemini Synthesis", "RUNNING", "Generating final response...")
        
        # Construct Prompt
        system_prompt = (
            f"VAI TR√í: B·∫°n l√† H·ªá th·ªëng SI√äU TR√ç TU·ªÜ K·ª≤ M√îN (Orchestrated AI).\n"
            f"B·∫†N PH·∫¢I TR·∫¢ L·ªúI CH√çNH X√ÅC THEO C√ÅC NGU·ªíN D·ªÆ LI·ªÜU ƒê∆Ø·ª¢C CUNG C·∫§P D∆Ø·ªöI ƒê√ÇY:\n"
            f"{history_context}\n"
            f"{knowledge_context}\n"
            f"--------------------------------------------------\n"
            f"C√ÇU H·ªéI NG∆Ø·ªúI D√ôNG: '{user_question}'\n\n"
            f"QUY T·∫ÆC B·∫ÆT BU·ªòC:\n"
            f"1. B·∫ÆT BU·ªòC cƒÉn c·ª© v√†o [D·ªÆ LI·ªÜU B√ÄN C·ªú ƒêANG HI·ªÇN TH·ªä] (n·∫øu c√≥) ƒë·ªÉ ƒë∆∞a ra k·∫øt lu·∫≠n. KH√îNG TR·∫¢ L·ªúI CHUNG CHUNG.\n"
            f"2. B·∫ÆT BU·ªòC x√°c ƒë·ªãnh ƒë√∫ng ƒë·ªëi t∆∞·ª£ng (D·ª•ng Th·∫ßn) c·∫ßn xem t·ª´ [B·∫¢NG TRA C·ª®U ƒê·ªêI T∆Ø·ª¢NG].\n"
            f"3. N·∫øu c√¢u h·ªèi v·ªÅ con ng∆∞·ªùi (ai, trai, g√°i) m√† d·ªØ li·ªáu cung c·∫•p ch·ªâ n√≥i v·ªÅ ch·ªß ƒë·ªÅ kh√°c (nh∆∞ B√°n nh√†), h√£y B·ªé QUA ch·ªß ƒë·ªÅ ƒë√≥ v√† ch·ªâ d√πng [B·∫¢NG TRA C·ª®U ƒê·ªêI T∆Ø·ª¢NG] v√† [T·ª™ ƒêI·ªÇN T√çNH C√ÅCH] ƒë·ªÉ tr·∫£ l·ªùi.\n"
            f"4. TR√åNH B√ÄY: \n"
            f"   - D√πng [SUY_LUAN]...[/SUY_LUAN] ƒë·ªÉ gi·∫£i th√≠ch quy tr√¨nh t∆∞ duy.\n"
            f"   - D√πng [KET_LUAN]...[/KET_LUAN] ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi cu·ªëi c√πng.\n"
            f"5. Tuy·ªát ƒë·ªëi kh√¥ng t·ª± √Ω b·ªãa ƒë·∫∑t th√¥ng tin n·∫øu d·ªØ li·ªáu kh√¥ng c√≥.\n"
        )
        
        final_answer = self.gemini._call_ai(system_prompt)
        return final_answer

    def _format_live_context(self, qmdg, mai_hoa, luc_hao):
        """Helper to turn complex state into readable text for AI"""
        context = ""
        
        # 1. QMDG Grid
        if qmdg:
            context += "--- K·ª≤ M√îN ƒê·ªòN GI√ÅP ---\n"
            # Extract basic 4 pillars if available
            context += f"T·ª© tr·ª•: {qmdg.get('can_nam')} {qmdg.get('chi_nam')} / {qmdg.get('can_thang')} {qmdg.get('chi_thang')} / {qmdg.get('can_ngay')} {qmdg.get('chi_ngay')} / {qmdg.get('can_gio')} {qmdg.get('chi_gio')}\n"
            context += f"Ti·∫øt kh√≠: {qmdg.get('tiet_khi')} | C·ª•c: {qmdg.get('cuc')} {'D∆∞∆°ng' if qmdg.get('is_duong_don') else '√Çm'}\n"
            
            # Extract 9 palaces
            for i in range(1, 10):
                sao = qmdg.get('thien_ban', {}).get(i, "N/A")
                mon = qmdg.get('nhan_ban', {}).get(i, "N/A")
                than = qmdg.get('than_ban', {}).get(i, "N/A")
                c_thien = qmdg.get('can_thien_ban', {}).get(i, "N/A")
                c_dia = qmdg.get('dia_can', {}).get(i, "N/A")
                context += f"- Cung {i}: {sao}, {mon}, {than}, Thi√™n Can {c_thien} l√¢m {c_dia}\n"

        # 2. Mai Hoa
        if mai_hoa:
            context += "\n--- MAI HOA D·ªäCH S·ªê ---\n"
            context += f"Qu·∫ª Ch√≠nh: {mai_hoa.get('ten')} (Th·ªÉ: {mai_hoa.get('ten_the')}, D·ª•ng: {mai_hoa.get('ten_dung')})\n"
            context += f"Quan h·ªá Ng≈© h√†nh: {mai_hoa.get('upper_element')} / {mai_hoa.get('lower_element')}\n"
            context += f"T∆∞·ª£ng Qu·∫ª: {mai_hoa.get('tuong')}\n"
            context += f"Qu·∫ª Bi·∫øn: {mai_hoa.get('ten_qua_bien')} (ƒê·ªông h√†o {mai_hoa.get('dong_hao')})\n"

        # 3. L·ª•c H√†o
        if luc_hao:
            context += "\n--- L·ª§C H√ÄO ---\n"
            context += f"Qu·∫ª: {luc_hao.get('ten_que')}\n"
            context += f"D·ª•ng Th·∫ßn: {luc_hao.get('dung_than_label')}\n"
            context += f"Tr·∫°ng th√°i Th·∫ø/·ª®ng: {luc_hao.get('the_ung_interaction')}\n"
            
        return context
        
    def render_logs(self):
        """Render the n8n-style execution steps in Streamlit"""
        st.markdown("### ‚öôÔ∏è Quy Tr√¨nh X·ª≠ L√Ω (System Workflow)")
        for log in self.logs:
            icon = "‚úÖ" if log['status'] in ["SUCCESS", "COMPLETED"] else "üîÑ"
            if log['status'] == "ERROR": icon = "‚ùå"
            
            with st.expander(f"{icon} {log['step']} - {log['status']}", expanded=False):
                st.write(f"**Time:** {log['time']}")
                st.write(f"**Detail:** {log['detail']}")
